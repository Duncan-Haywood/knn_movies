{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "varying-incidence",
   "metadata": {},
   "source": [
    "Some goals of this code is to keep every cell and function in the form of pure functions, to document well, and to keep small the functions. I would greatly appreciate any contributions following the same guidelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collaborative-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "## incase any packages aren't installed, you can uncomment and run this following line. \n",
    "# !pip3 install nltk sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empty-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-martial",
   "metadata": {},
   "source": [
    "# Phase One: loading and cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affecting-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_into_reviews():\n",
    "    \"\"\"returns list of each individual review\"\"\"\n",
    "    with open('./data/small_train.txt') as text:\n",
    "        review = text.readline()\n",
    "        reviews = list()\n",
    "        while review:\n",
    "            reviews.append(review)\n",
    "            review = text.readline()\n",
    "    return reviews\n",
    "reviews_list = load_into_reviews()\n",
    "## check if loaded correctly\n",
    "# print('reviews number:', len(reviews_list),'\\nfirst review:', reviews_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grand-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if correctly loaded\n",
    "def is_one_review_per_entry(reviews_list):\n",
    "    \"\"\"returns dict of incorrect reviews\"\"\"\n",
    "    incorrects = dict()\n",
    "    end_tag = '#EOF'\n",
    "    for index, review in enumerate(reviews_list):\n",
    "        end_tags_count = review.count(end_tag) ## returns how many times the tag appears\n",
    "        if end_tags_count!=1:\n",
    "            incorrects[index]=end_tags_count ## stores the count and the index for future reference. \n",
    "    return incorrects\n",
    "incorrect_readins = is_one_review_per_entry(reviews_list)\n",
    "## check results:\n",
    "# print('length of incorrect_readins:', len(incorrect_readins)) ## should equal zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stuffed-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenizing reviews\n",
    "def to_tokenized_list(reviews_list):\n",
    "    \"\"\"returns list of reviews where reviews are lists of tokens\"\"\"\n",
    "    tokenized_reviews_list = list()\n",
    "    for review in reviews_list:\n",
    "        tokens = word_tokenize(review)\n",
    "        tokenized_reviews_list.append(tokens)\n",
    "    return tokenized_reviews_list\n",
    "tokenized_reviews_list = to_tokenized_list(reviews_list)\n",
    "## check if loaded correctly\n",
    "# print('reviews number:', len(tokenized_reviews_list), '\\nfirst tokenized review:', tokenized_reviews_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "alleged-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing extra tokens. \n",
    "def remove_extra_tokens(tokenized_reviews_list):\n",
    "    \"\"\"returns list of reviews where reviews are lists of tokens and some extraneous tokens are removed\"\"\"\n",
    "    clean_reviews_list = list()\n",
    "    for review in tokenized_reviews_list:\n",
    "        ## only tokens neither in punctuation or stopwords\n",
    "        clean_review = [token for token in review if token not in punctuation and token not in stopwords.words('english')]\n",
    "        clean_reviews_list.append(clean_review)\n",
    "    return clean_reviews_list\n",
    "clean_reviews_list = remove_extra_tokens(tokenized_reviews_list)\n",
    "# print('first cleaned review', clean_reviews_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "black-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "## more cleaning could be done at this point to improve quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "minimal-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(clean_reviews_list):\n",
    "    \"\"\"returns ratings and returns clean_reviews_list without the ratings\"\"\"\n",
    "    ratings_y = list()\n",
    "    for review in clean_reviews_list:\n",
    "        rating = int(review[0])\n",
    "        ratings_y.append(rating)\n",
    "    return ratings_y\n",
    "ratings_y = get_ratings(clean_reviews_list)\n",
    "## check to see if works\n",
    "# print('ratings', ratings_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "first-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ratings_from_reviews_list(clean_reviews_list):\n",
    "    \"\"\"returns same list without the first token of each review\"\"\"\n",
    "    shortened_list = [review[1:-1] for review in clean_reviews_list]\n",
    "    return shortened_list\n",
    "clean_shortened_reviews_list = remove_ratings_from_reviews_list(clean_reviews_list)\n",
    "## check to see if it works\n",
    "# print(clean_shortened_reviews_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-presentation",
   "metadata": {},
   "source": [
    "# Phase Two: vectorizing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-velvet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
