{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "peripheral-acquisition",
   "metadata": {},
   "source": [
    "Some goals of this code is to keep every cell and function in the form of pure functions, to document well, and to keep small the functions. I would greatly appreciate any contributions following the same guidelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latin-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "## incase any packages aren't installed, you can uncomment and run this following line. \n",
    "# !pip3 install nltk pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "diverse-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-newcastle",
   "metadata": {},
   "source": [
    "# Phase One: loading and cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "residential-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_into_reviews(path='./data/small_train.txt'):\n",
    "    \"\"\"returns list of each individual review\"\"\"\n",
    "    with open(path) as text:\n",
    "        review = text.readline()\n",
    "        reviews = list()\n",
    "        while review:\n",
    "            reviews.append(review)\n",
    "            review = text.readline()\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continuous-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(reviews_list):\n",
    "    \"\"\"returns ratings from list of strings with first word as the rating\"\"\"\n",
    "    ratings_y = list()\n",
    "    for review in reviews_list:\n",
    "        rating = review.split(\"\\t\")[0]\n",
    "        ratings_y.append(rating)\n",
    "    return ratings_y\n",
    "def remove_ratings(reviews_list):\n",
    "    shortened_reviews_list = [review.split('\\t', 1)[1] for review in reviews_list]\n",
    "    return shortened_reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "desperate-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if correctly loaded\n",
    "def is_one_review_per_entry(reviews_list):\n",
    "    \"\"\"returns dict of incorrect reviews\"\"\"\n",
    "    incorrects = dict()\n",
    "    end_tag = '#EOF'\n",
    "    for index, review in enumerate(reviews_list):\n",
    "        end_tags_count = review.count(end_tag) ## returns how many times the tag appears\n",
    "        if end_tags_count!=1:\n",
    "            incorrects[index]=end_tags_count ## stores the count and the index for future reference.\n",
    "    return incorrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "angry-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenizing reviews\n",
    "def to_tokenized_list(reviews_list):\n",
    "    \"\"\"returns list of reviews where reviews are lists of tokens\"\"\"\n",
    "    tokenized_reviews_list = list()\n",
    "    for review in reviews_list:\n",
    "        tokens = word_tokenize(review)\n",
    "        tokenized_reviews_list.append(tokens)\n",
    "    return tokenized_reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "southwest-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing extra tokens. \n",
    "def remove_extra_tokens(token_reviews_list):\n",
    "    \"\"\"returns list of reviews where reviews are lists of tokens and some extraneous tokens are removed\"\"\"\n",
    "    clean_reviews_list = list()\n",
    "    for review in token_reviews_list:\n",
    "        ## only tokens neither in punctuation or stopwords\n",
    "        clean_review = [token for token in review if token not in punctuation and token not in stopwords.words('english')]\n",
    "        clean_reviews_list.append(clean_review)\n",
    "    return clean_reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "constitutional-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "## more cleaning could be done at this point to improve quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "domestic-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "## final preprocessing for tokenizer use. \n",
    "def stringify_reviews_tokens(token_reviews_list):\n",
    "    string_reviews = list()\n",
    "    for review_tokens in token_reviews_list:\n",
    "        review = ' '.join(review_tokens)\n",
    "        string_reviews.append(review)\n",
    "    return string_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-midnight",
   "metadata": {},
   "source": [
    "## Saving for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "automatic-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saves cleaned tokens and strings for use in next steps\n",
    "def reviews_to_df(ratings_y, clean_token_reviews, clean_reviews, short_reviews_list):\n",
    "    reviews_df = pd.DataFrame()\n",
    "    reviews_df['ratings'] = ratings_y\n",
    "    reviews_df['tokens'] = clean_token_reviews\n",
    "    reviews_df['clean_reviews'] = clean_reviews\n",
    "    reviews_df['raw_reviews'] = short_reviews_list\n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alpine-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(reviews_df):\n",
    "    reviews_df.to_pickle('./data/reviews_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "duplicate-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(load_path, save_path):\n",
    "    reviews_list = load_into_reviews(load_path)\n",
    "    ratings_y = get_ratings(reviews_list)\n",
    "    incorrect_readins = is_one_review_per_entry(reviews_list)\n",
    "    assert (len(incorrect_readins) == 0), 'incorrect readins'\n",
    "    short_reviews_list = remove_ratings(reviews_list)\n",
    "    token_reviews_list = to_tokenized_list(short_reviews_list)\n",
    "    clean_token_reviews = remove_extra_tokens(token_reviews_list)\n",
    "    clean_reviews = stringify_reviews_tokens(clean_token_reviews)\n",
    "    reviews_df = reviews_to_df(ratings_y, clean_token_reviews, clean_reviews, short_reviews_list)\n",
    "    save_df(reviews_df)\n",
    "    df = pd.read_pickle(save_path)\n",
    "    return df.head()\n",
    "def main():\n",
    "    load_path = './data/small_train.txt'\n",
    "    save_path = './data/reviews_df.pickle'\n",
    "    df = run(load_path, save_path)\n",
    "    print(df)\n",
    "#     load_path = './data/small_test.txt'\n",
    "#     save_path = './data/reviews_df_test.pickle'\n",
    "#     df = run(load_path, save_path)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "grave-apartment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ratings                                             tokens  \\\n",
      "0      +1  [One, all-time, favorite, so-laughably-lousy-t...   \n",
      "1      -1  [I, high, hopes, film, I, thought, CLEAN, SHAV...   \n",
      "2      -1  [When, released, I, thought, one, profane, fil...   \n",
      "3      -1  [I, watched, movie, Starz, Let, go, things, th...   \n",
      "4      +1  [I, loved, much, I, bought, DVD, novel, time, ...   \n",
      "\n",
      "                                       clean_reviews  \\\n",
      "0  One all-time favorite so-laughably-lousy-that-...   \n",
      "1  I high hopes film I thought CLEAN SHAVEN Kerri...   \n",
      "2  When released I thought one profane films ever...   \n",
      "3  I watched movie Starz Let go things thought co...   \n",
      "4  I loved much I bought DVD novel time The chemi...   \n",
      "\n",
      "                                         raw_reviews  \n",
      "0  One of my all-time favorite so-laughably-lousy...  \n",
      "1  I had high hopes for this film, because I thou...  \n",
      "2  When this was released, I thought this was one...  \n",
      "3  I just watched this movie on Starz. Let me go ...  \n",
      "4  I loved it so much that I bought the DVD and t...  \n",
      "  ratings                                             tokens  \\\n",
      "0      +1  [One, all-time, favorite, so-laughably-lousy-t...   \n",
      "1      -1  [I, high, hopes, film, I, thought, CLEAN, SHAV...   \n",
      "2      -1  [When, released, I, thought, one, profane, fil...   \n",
      "3      -1  [I, watched, movie, Starz, Let, go, things, th...   \n",
      "4      +1  [I, loved, much, I, bought, DVD, novel, time, ...   \n",
      "\n",
      "                                       clean_reviews  \\\n",
      "0  One all-time favorite so-laughably-lousy-that-...   \n",
      "1  I high hopes film I thought CLEAN SHAVEN Kerri...   \n",
      "2  When released I thought one profane films ever...   \n",
      "3  I watched movie Starz Let go things thought co...   \n",
      "4  I loved much I bought DVD novel time The chemi...   \n",
      "\n",
      "                                         raw_reviews  \n",
      "0  One of my all-time favorite so-laughably-lousy...  \n",
      "1  I had high hopes for this film, because I thou...  \n",
      "2  When this was released, I thought this was one...  \n",
      "3  I just watched this movie on Starz. Let me go ...  \n",
      "4  I loved it so much that I bought the DVD and t...  \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-blank",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
